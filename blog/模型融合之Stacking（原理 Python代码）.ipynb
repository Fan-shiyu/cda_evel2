{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据来源于天池赛题：零基础入门数据挖掘 - 二手车交易价格预测\n",
    "\n",
    "地址：https://tianchi.aliyun.com/competition/entrance/231784/introduction?spm=5176.12281957.1004.1.38b02448ausjSX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、原理介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在数据挖掘过程中，单个模型的泛化能力往往比较单薄，而模型融合的方法可以结合多个模型的优点，提升模型的预测精度。典型的模型融合的方法有加权融合、Stacking/Blending、提升树。下面将以Stacking为例，做一个详细介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stacking是一种多层模型，将已训练好的多个模型作为基分类器。然后将这几个学习器的预测结果作为新的训练集，来学习一个新的学习器。\n",
    "* 即可以看成是一种结合策略，使用另外一个机器学习算法来将个体机器学习器的结果结合在一起。\n",
    "* 我们称第一层学习器为初级学习器，称第二层学习器为次级学习器。\n",
    "* 通常情况下，为了防止过拟合，次级学习器宜选用简单模型。如在回归问题中，可以使用线性回归；在分类问题中，可以使用logistic。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载需要的模块\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error,  make_scorer\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据读取\n",
    "Train_data = pd.read_csv('F:/data/used_car_train_20200313.csv', sep=' ')\n",
    "TestA_data = pd.read_csv('F:/data/used_car_testA_20200313.csv', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择前面特征工程过程中筛选出的特征\n",
    "Train_data=Train_data[['v_12','v_10','v_9','v_11','price']]\n",
    "TestA_data=TestA_data[['v_12','v_10','v_9','v_11']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述特征的筛选过程可以参考前面的文章\n",
    "\n",
    "链接：https://blog.csdn.net/weixin_45481473/article/details/105159419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分自变量和目标变量\n",
    "X_data = Train_data.drop('price', axis=1) #删除列\n",
    "Y_data = Train_data['price']\n",
    "X_test  = TestA_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "def build_model_gbdt(x_train,y_train):\n",
    "    estimator =GradientBoostingRegressor(loss='ls',subsample= 0.85,max_depth= 5,n_estimators = 100)\n",
    "    param_grid = { \n",
    "            'learning_rate': [0.05,0.08,0.1,0.2],\n",
    "            }\n",
    "    gbdt = GridSearchCV(estimator, param_grid,cv=3)\n",
    "    gbdt.fit(x_train,y_train)\n",
    "    print(gbdt.best_params_)\n",
    "    # print(gbdt.best_estimator_ )\n",
    "    return gbdt\n",
    "\n",
    "def build_model_xgb(x_train,y_train):\n",
    "    model = xgb.XGBRegressor(n_estimators=120, learning_rate=0.08, gamma=0, subsample=0.8,\\\n",
    "        colsample_bytree=0.9, max_depth=5) #, objective ='reg:squarederror'\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def build_model_lgb(x_train,y_train):\n",
    "    estimator = lgb.LGBMRegressor(num_leaves=63,n_estimators = 100)\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "    }\n",
    "    gbm = GridSearchCV(estimator, param_grid)\n",
    "    gbm.fit(x_train, y_train)\n",
    "    return gbm\n",
    "\n",
    "def build_model_lr(x_train,y_train):\n",
    "    reg_model = linear_model.LinearRegression()\n",
    "    reg_model.fit(x_train,y_train)\n",
    "    return reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict GBDT...\n",
      "{'learning_rate': 0.1}\n",
      "predict XGB...\n",
      "[19:06:12] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "predict lgb...\n"
     ]
    }
   ],
   "source": [
    "#交叉验证\n",
    "#划分训练集和测试集\n",
    "x_train,x_val,y_train,y_val = train_test_split(X_data,Y_data,test_size=0.3)\n",
    "\n",
    "#训练模型\n",
    "print('Predict GBDT...')\n",
    "model_gbdt = build_model_gbdt(x_train,y_train)\n",
    "val_gbdt = model_gbdt.predict(x_val)\n",
    "subA_gbdt = model_gbdt.predict(X_test)\n",
    "\n",
    "print('predict XGB...')\n",
    "model_xgb = build_model_xgb(x_train,y_train)\n",
    "val_xgb = model_xgb.predict(x_val)\n",
    "subA_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "print('predict lgb...')\n",
    "model_lgb = build_model_lgb(x_train,y_train)\n",
    "val_lgb = model_lgb.predict(x_val)\n",
    "subA_lgb = model_lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在初级学习器中，一共建立了三个模型，分别是LightGBM、GBDT、XGBoost。\n",
    "\n",
    "关于XGBoost模型的原理和代码实现，可以参考链接：https://blog.csdn.net/weixin_45481473/article/details/105234922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starking\n",
    "#第一层\n",
    "train_lgb_pred = model_lgb.predict(x_train)\n",
    "train_xgb_pred = model_xgb.predict(x_train)\n",
    "train_gbdt_pred = model_gbdt.predict(x_train)\n",
    "\n",
    "Strak_X_train = pd.DataFrame()\n",
    "Strak_X_train['Method_1'] = train_lgb_pred\n",
    "Strak_X_train['Method_2'] = train_xgb_pred\n",
    "Strak_X_train['Method_3'] = train_gbdt_pred\n",
    "\n",
    "Strak_X_val = pd.DataFrame()\n",
    "Strak_X_val['Method_1'] = val_lgb\n",
    "Strak_X_val['Method_2'] = val_xgb\n",
    "Strak_X_val['Method_3'] = val_gbdt\n",
    "\n",
    "Strak_X_test = pd.DataFrame()\n",
    "Strak_X_test['Method_1'] = subA_lgb\n",
    "Strak_X_test['Method_2'] = subA_xgb\n",
    "Strak_X_test['Method_3'] = subA_gbdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里将线性回归作为次级学习器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Stacking-LR: 914.5652539316941\n",
      "MAE of Stacking-LR: 961.6758318716319\n",
      "Predict Stacking-LR...\n"
     ]
    }
   ],
   "source": [
    "#第二层\n",
    "model_lr_Stacking = build_model_lr(Strak_X_train,y_train)\n",
    "\n",
    "#训练集\n",
    "train_pre_Stacking = model_lr_Stacking.predict(Strak_X_train)\n",
    "print('MAE of Stacking-LR:',mean_absolute_error(y_train,train_pre_Stacking))\n",
    "\n",
    "#验证集\n",
    "val_pre_Stacking = model_lr_Stacking.predict(Strak_X_val)\n",
    "print('MAE of Stacking-LR:',mean_absolute_error(y_val,val_pre_Stacking))\n",
    "\n",
    "#预测集\n",
    "print('Predict Stacking-LR...')\n",
    "subA_Stacking = model_lr_Stacking.predict(Strak_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、结果解读"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 从模型结果可以看出，Stacking融合之后模型的MAE达到了914.5652539316941。这相较于前文使用的单个XGBoost模型，平均绝对误差有所减小。说明Stacking在一定程度上提升了模型精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 在验证集中，MAE=961.6758318716319，略大于训练集上的MAE。说明模型存在轻微的过拟合，这也是后面模型改进的一个方向。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
