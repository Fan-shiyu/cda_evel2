{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据来源于天池赛题：零基础入门数据分析-学术前沿趋势分析\t\n",
    "地址：https://tianchi.aliyun.com/competition/entrance/531866/information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、原理介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF方法常用来评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。在一个特定文件中，当某类词语出现的频率较高，同时该类词语在整个语料库中出现频率较低时，该类词语的TF-IDF就会比较高。\n",
    "\n",
    "TF-IDF在中文中指词频-逆向文件频率，由TF（词频）和IDF（逆向文件频率）两个部分组成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，TF（词频）指的是某一个给定的词语在该文件中出现的次数，TF的计算公式为：\n",
    "\n",
    "$$ TF_{w}=\\frac{在某一类中词条w出现的次数}{该类中所有的词条数目} $$\n",
    "\n",
    "IDF（逆向文件频率）的主要思想是：如果包含词条t的文档越少, IDF越大，则说明词条具有很好的类别区分能力。TDF的计算公式为：\n",
    "\n",
    "$$ IDF=log\\left ( \\frac{语料库的文档总数}{包含词条w的文档数+1}\\right )$$\n",
    "\n",
    "公式中分母之所以要加1，是为了避免分母为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里通过对计算机领域论文的标题和摘要进行文本特征提取，并根据这些文本特征来训练多分类模型，以此来识别不同类型的论文。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的package\n",
    "import seaborn as sns #用于画图\n",
    "from bs4 import BeautifulSoup #用于爬取arxiv的数据\n",
    "import re #用于正则表达式，匹配字符串的模式\n",
    "import requests #用于网络连接，发送网络请求，使用域名获取对应信息\n",
    "import json #读取数据，我们的数据为json格式的\n",
    "import pandas as pd #数据处理，数据分析\n",
    "import matplotlib.pyplot as plt #画图工具\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #过滤掉警告的意思\n",
    "from pyforest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#定义读取文本数据的函数\n",
    "def readArxivFile(path, columns=['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi',\n",
    "       'report-no', 'categories', 'license', 'abstract', 'versions',\n",
    "       'update_date', 'authors_parsed'], count=None):\n",
    "    '''\n",
    "    定义读取文件的函数\n",
    "        path: 文件路径\n",
    "        columns: 需要选择的列\n",
    "        count: 读取行数\n",
    "    '''\n",
    "    \n",
    "    data  = []\n",
    "    with open(path, 'r') as f: \n",
    "        for idx, line in enumerate(f): \n",
    "            if idx == count:\n",
    "                break\n",
    "                \n",
    "            d = json.loads(line)\n",
    "            d = {col : d[col] for col in columns}\n",
    "            data.append(d)\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    return data\n",
    "\n",
    "data = readArxivFile('F:/data/arxiv-metadata-oai-2019.json', \n",
    "                     ['id', 'title', 'categories', 'abstract'],\n",
    "                    200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0297</td>\n",
       "      <td>Remnant evolution after a carbon-oxygen white ...</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>We systematically explore the evolution of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0342</td>\n",
       "      <td>Cofibrations in the Category of Frolicher Spac...</td>\n",
       "      <td>math.AT</td>\n",
       "      <td>Cofibrations are defined in the category of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0360</td>\n",
       "      <td>Torsional oscillations of longitudinally inhom...</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>We explore the effect of an inhomogeneous ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0525</td>\n",
       "      <td>On the Energy-Momentum Problem in Static Einst...</td>\n",
       "      <td>gr-qc</td>\n",
       "      <td>This paper has been removed by arXiv adminis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0535</td>\n",
       "      <td>The Formation of Globular Cluster Systems in M...</td>\n",
       "      <td>astro-ph</td>\n",
       "      <td>The most massive elliptical galaxies show a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title categories  \\\n",
       "0  0704.0297  Remnant evolution after a carbon-oxygen white ...   astro-ph   \n",
       "1  0704.0342  Cofibrations in the Category of Frolicher Spac...    math.AT   \n",
       "2  0704.0360  Torsional oscillations of longitudinally inhom...   astro-ph   \n",
       "3  0704.0525  On the Energy-Momentum Problem in Static Einst...      gr-qc   \n",
       "4  0704.0535  The Formation of Globular Cluster Systems in M...   astro-ph   \n",
       "\n",
       "                                            abstract  \n",
       "0    We systematically explore the evolution of t...  \n",
       "1    Cofibrations are defined in the category of ...  \n",
       "2    We explore the effect of an inhomogeneous ma...  \n",
       "3    This paper has been removed by arXiv adminis...  \n",
       "4    The most massive elliptical galaxies show a ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看数据前五行\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据中的'title'列与'abstract'列进行合并，便于后续分类模型的训练\n",
    "data['text'] = data['title'] + data['abstract']\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: x.replace('\\n',' '))\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data = data.drop(['abstract', 'title'], axis=1) #删除原有的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对数据中的多个类别和单个类别进行处理\n",
    "# 多个类别，包含子分类\n",
    "data['categories'] = data['categories'].apply(lambda x : x.split(' '))\n",
    "\n",
    "# 单个类别，不包含子分类\n",
    "data['categories_big'] = data['categories'].apply(lambda x : [xx.split('.')[0] for xx in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对数据进行类别编码\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "data_label = mlb.fit_transform(data['categories_big'].iloc[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170618, 34)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2使用TF-IDF提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=4000,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=4000) #提取特征，限定特征提取数量不超过4000个\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf = vectorizer.fit_transform(data['text'].iloc[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3建立分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和验证集\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_tfidf, data_label,\n",
    "                                                 test_size = 0.2,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                              fit_prior=True),\n",
       "                      n_jobs=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建多标签分类模型\n",
    "#这里使用先验为多项式分布的朴素贝叶斯模型\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "clf = MultiOutputClassifier(MultinomialNB()).fit(x_train, y_train)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.91      0.85      0.88      3625\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.77      0.76      0.77      3801\n",
      "           9       0.84      0.89      0.86     10715\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00       186\n",
      "          12       0.44      0.41      0.42      1621\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.75      0.59      0.66      1096\n",
      "          15       0.61      0.80      0.69      1078\n",
      "          16       0.90      0.19      0.32       242\n",
      "          17       0.53      0.67      0.59      1451\n",
      "          18       0.71      0.54      0.62      1400\n",
      "          19       0.88      0.84      0.86     10243\n",
      "          20       0.40      0.09      0.15       934\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       0.87      0.03      0.06       414\n",
      "          23       0.48      0.65      0.55       517\n",
      "          24       0.37      0.33      0.35       539\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.60      0.42      0.49      3891\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.82      0.08      0.15       676\n",
      "          29       0.86      0.12      0.21       297\n",
      "          30       0.80      0.40      0.53      1714\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.56      0.65      0.60      3398\n",
      "          33       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.76      0.70      0.72     47851\n",
      "   macro avg       0.39      0.27      0.29     47851\n",
      "weighted avg       0.75      0.70      0.71     47851\n",
      " samples avg       0.74      0.76      0.72     47851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#评估模型拟合效果，输出分类模型报告\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、结果解释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面文本分类模型的评估结果中，precision表示查准率，recall表示查全率，f1-score表示F1值，support表示准确分类的论文数量。从评估结果可以看出，在模型训练的33个类别中，不同类别上的准确率差异很大。平均而言，准确率有百分之七十多。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
